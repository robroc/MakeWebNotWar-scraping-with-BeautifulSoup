{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping websites with BeautifulSoup\n",
    "\n",
    "This is a basic walkthrough of harvesting data from websites that have infromation spread across multiple pages and inside links.\n",
    "\n",
    "We'll be scraping the database of food recall warnings from the [Canadian Food Inspection Agency](http://www.inspection.gc.ca/about-the-cfia/newsroom/food-recall-warnings/complete-listing/eng/1351519587174/1351519588221).\n",
    "\n",
    "First, the set-up. This tutorial uses Python 2.7 and three modules that need to be installed:\n",
    "\n",
    "* [requests](http://docs.python-requests.org/en/latest/) for HTTP\n",
    "* [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) for parsing HTML\n",
    "* [unicodecsv](https://github.com/jdunck/python-unicodecsv) for saving the data to a CSV without worrying about Unicode errors\n",
    "\n",
    "Install them in the command line with with pip:\n",
    "\n",
    "    $ pip install requests, beautifulsoup4, unicodecsv\n",
    "\n",
    "## Study the site structure\n",
    "\n",
    "First, we need to spend time on the site to understand how the website is built. What's the URL structure? What's the general DOM structure?\n",
    "\n",
    "By poking around a bit and selecting a year in the top menu, we see that the site lists all warnings for that year. Good, less pagination work for us.\n",
    "\n",
    "That year is also specified in the '`ay=`' parameter in the URL. And if you change that parameter to another year, all the warnins for that year are loaded.\n",
    "\n",
    "<img src=\"img/url.png\">\n",
    "\n",
    "This will help us cycle through the different years.\n",
    "\n",
    "So let's set up our first task, which is cycling through the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef cycle_years(start_year, end_year):\\n\\n    for year in range(start_year, end_year + 1):\\n        r = requests.get(url_head + str(year) + url_tail)\\n        # Load the raw HTML into a BeautifulSoup object\\n        soup = BeautifulSoup(r.content, \"lxml\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Concatenate the URL up to 'ay=' with the year we want, then the tail end\n",
    "url_head = \"http://www.inspection.gc.ca/about-the-cfia/newsroom/food-recall-warnings/complete-listing/eng/1351519587174/1351519588221?ay=\"\n",
    "url_tail = \"&fr=0&fc=0&fd=0&ft=1\"\n",
    "\n",
    "def cycle_years(start_year, end_year):\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        r = requests.get(url_head + str(year) + url_tail)\n",
    "        # Load the raw HTML into a BeautifulSoup object\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave this for now and come back to it later. \n",
    "\n",
    "We'll first look at how BeautifulSoup works at parsing a DOM. Let's load just the index page for 2015 recalls and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"http://www.inspection.gc.ca/about-the-cfia/newsroom/food-recall-warnings/complete-listing/eng/1351519587174/1351519588221?ay=2015&fr=0&fc=0&fd=0&ft=1\")\n",
    "soup = BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 9]><html class=\"no-js lt-ie9\" lang=\"en\" dir=\"ltr\"><![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" dir=\"ltr\" lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   Complete listing of all recalls and allergy alerts  - About the Canadian Food Inspection Agency - Canadian Food Inspection Agency\n",
      "  </title>\n",
      "  <meta content=\"Complete listing of all recalls and allergy alerts\" name=\"dcterms.title\"/>\n",
      "  <meta content=\"Canadian Food Inspection Agency\" name=\"description\"/>\n",
      "  <meta content=\"Canadian Food Inspection Agency\" name=\"dcterms.description\"/>\n",
      "  <meta content=\"Canadian Food Inspection Agency\" name=\"keywords\"/>\n",
      "  <meta content=\"inspection\" name=\"dcterms.subject\" title=\"gccore\"/>\n",
      "  <meta content=\"Government of Canada,Canadian Food Inspection Agency\" name=\"dcterms.creator\"/>\n",
      "  <meta content=\"eng\" name=\"dcterms.language\" title=\"ISO639-2\"/>\n",
      "  <meta content=\"2012-10-\n"
     ]
    }
   ],
   "source": [
    "# The variable soup is a BeautifulSoup object containing the entire HTML document.\n",
    "\n",
    "# Use prettify() to pretty-print the document\n",
    "print soup.prettify()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\\n<meta charset=\"unicode-escape\"/>\\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\\n<title>Complete listing of all recalls and allergy alerts  - About the Canadian Food Inspection Agency - Canadian Food Inspection Agency</title>\\n<meta content=\"Complete listing of all recalls and allergy alerts\" name=\"dcterms.title\"/>\\n<meta content=\"Canadian Food Inspection Agency\" name=\"description\"/>\\n<meta content=\"Canadian Food Inspection Agency\" name=\"dcterms.description\"/>\\n<meta content=\"Canadian Food Inspection Agency\" name=\"keywords\"/>\\n<meta content=\"inspection\" name=\"dcterms.subject\" title=\"gccore\"/>\\n<meta content=\"Government of Canada,Canadian Food Inspection Agency\" name=\"dcterms.creator\"/>\\n<meta content=\"eng\" name=\"dcterms.language\" title=\"ISO639-2\"/>\\n<meta content=\"2012-10-29 10:06:27\" name=\"dcterms.issued\" title=\"W3CDTF\"/>\\n<meta content=\"2013-09-24\" name=\"dcterms.modified\" title=\"W3CDTF\"/>\\n<!--[if gte IE 9 | !IE ]><!-->\\n<link href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/assets/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>\\n<link href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/css/theme.min.css\" rel=\"stylesheet\"/>\\n<!--<![endif]-->\\n<!--[if lt IE 9]>\\n\\t\\t<link href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/assets/favicon.ico\" rel=\"shortcut icon\" />\\n\\t\\t<link rel=\"stylesheet\" href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/css/ie8-theme.min.css\" />\\n\\t\\t<script src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js\"></script>\\n\\t\\t<script src=\"/DAM/PresentationService/WET/4.0.19/wet-boew/js/ie8-wet-boew.min.js\"></script>\\n\\t\\t<![endif]-->\\n<noscript><link href=\"/DAM/PresentationService/WET/4.0.19/wet-boew/css/noscript.min.css\" rel=\"stylesheet\"/></noscript>\\n<link href=\"http://ic.gc.ca/eic/site/icgc.nsf/vwapj/loop11.css/$file/loop11.css\" rel=\"stylesheet\"/>\\n</head>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's a big mess, but we can start navigating and searching the DOM for the elements we want.\n",
    "# You can access some nodes directly:\n",
    "\n",
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Complete listing of all recalls and allergy alerts  - About the Canadian Food Inspection Agency - Canadian Food Inspection Agency</title>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example:\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<link href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/assets/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can keep going deeper, and really target the node we want. \n",
    "\n",
    "soup.head.link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<link href=\"/DAM/PresentationService/WET/4.0.19/theme-gcwu-fegc/css/theme.min.css\" rel=\"stylesheet\"/>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are several link nodes, but BeautifulSoup returns the first one it finds.\n",
    "# What if we want the link to the CSS stylesheet?\n",
    "\n",
    "soup.head.find(\"link\", {\"rel\" : \"stylesheet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"wb-sl\" href=\"#wb-cont\">Skip to main content</a>,\n",
       " <a class=\"wb-sl\" href=\"#wb-info\">Skip to \"About this site\"</a>,\n",
       " <a class=\"wb-sl\" href=\"#wb-sec\">Skip to section menu</a>,\n",
       " <a href=\"http://www.canada.ca/en/index.html\" rel=\"external\">Canada.ca</a>,\n",
       " <a href=\"http://www.canada.ca/en/services/index.html\" rel=\"external\">Services</a>,\n",
       " <a href=\"http://www.canada.ca/en/government/dept/index.html\" rel=\"external\">Departments</a>,\n",
       " <a href=\"/au-sujet-de-l-acia/salle-de-nouvelles/avis-de-rappel-d-aliments/liste-complete/fra/1351519587174/1351519588221?ay=2015&amp;fr=0&amp;fc=0&amp;fd=0&amp;ft=1\" lang=\"fr\">Fran\\xe7ais</a>,\n",
       " <a aria-controls=\"mb-pnl\" class=\"overlay-lnk btn btn-sm btn-default\" href=\"#mb-pnl\" role=\"button\" title=\"Search and menus\"><span class=\"glyphicon glyphicon-search\"><span class=\"glyphicon glyphicon-th-list\"><span class=\"wb-inv\">Search and menus</span></span></span></a>,\n",
       " <a href=\"/eng/1297964599443/1297965645317\">Canadian Food Inspection Agency</a>,\n",
       " <a class=\"item\" href=\"#aboutthecfia\">About the <abbr title=\"Canadian Food Inspection Agency\">CFIA</abbr></a>,\n",
       " <a href=\"/about-the-cfia/acts-and-regulations/eng/1299846777345/1299847442232\">Acts and Regulations</a>,\n",
       " <a href=\"/about-the-cfia/permits-licences-and-approvals/eng/1395348112901/1395348237219\">Permits, Licences and Approvals</a>,\n",
       " <a href=\"/about-the-cfia/transforming-the-cfia/eng/1374871172385/1374871197211\">Transforming the <abbr title=\"Canadian Food Inspection Agency\">CFIA</abbr></a>,\n",
       " <a href=\"/about-the-cfia/accountability/eng/1299776530447/1299776743937\">Accountability</a>,\n",
       " <a href=\"/about-the-cfia/organizational-information/eng/1323224617636/1323224814073\">Organizational Information </a>,\n",
       " <a href=\"/about-the-cfia/newsroom/eng/1299073792503/1299076004509\">Newsroom</a>,\n",
       " <a href=\"/about-the-cfia/cfia-jobs/eng/1299857348736/1299857657230\"><abbr title=\"Canadian Food Inspection Agency\">CFIA</abbr> Jobs</a>,\n",
       " <a href=\"/about-the-cfia/forms-and-publications/eng/1328823159400/1328823230077\">Forms and Publications</a>,\n",
       " <a href=\"/about-the-cfia/eng/1299008020759/1299008778654\">About the <abbr title=\"Canadian Food Inspection Agency\">CFIA</abbr> - More</a>,\n",
       " <a class=\"item\" href=\"#food\">Food</a>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we want to get all the hyperlinks into a list:\n",
    "\n",
    "soup.find_all(\"a\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. But we don't want ALL the links, just the ones that go to the deails of the recalls. By inspecting the page with Chrome's developer tools, we see that those links are inside a table with classes \"table table-striped table-hover\" and then inside the `<tbody>` node.\n",
    "\n",
    "<img src=\"img/link_table.png\">\n",
    "\n",
    "So let's get those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<table class=\"table table-striped table-hover\">\\n <caption class=\"text-left mrgn-bttm-sm\">\\n  Food Recall Warnings and Allergy Alerts\\n </caption>\\n <thead>\\n  <tr>\\n   <th>\\n    Posted\\n   </th>\\n   <th>\\n    Recall\\n   </th>\\n   <th>\\n    Class\\n   </th>\\n   <th>\\n    Distribution\\n   </th>\\n  </tr>\\n </thead>\\n <tbody>\\n  <!-- WCMS:RECALL-LIST-ITEM BEGIN -->\\n  <tr>\\n   <td>\\n    2015-12-30\\n   </td>\\n   <td>\\n    <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-30/eng/1451509015225/1451509020606\" title=\"Updated Food Recall Warning (Allergen) - 2015-12-30\">\\n     Updated Food Recall Warning (Allergen) -\\n     <span lang=\"zh\">\\n      Bingquan\\n     </span>\\n     brand Ladies\\' Soy Drink recalled due to undeclared milk\\n    </a>\\n   </td>\\n   <td>\\n    Class 1\\n   </td>\\n   <td>\\n    Ontario\\n   </td>\\n  </tr>\\n  <!-- WCMS:RECALL-LIST-ITEM BEGIN -->\\n  <tr>\\n   <td>\\n    2015-12-23\\n   </td>\\n   <td>\\n    <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-23/eng/14509140011'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_table = soup.find(\"table\", class_ = \"table table-striped table-hover\")\n",
    "\n",
    "links_table.prettify()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table', 'table-striped', 'table-hover']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# links_table is also a BeautifulSoup object with all the same methods.\n",
    "# We can inspect its classes, for instance\n",
    "\n",
    "links_table[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see how many children nodes it has\n",
    "\n",
    "len(links_table.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-30/eng/1451509015225/1451509020606\" title=\"Updated Food Recall Warning (Allergen) - 2015-12-30\">Updated Food Recall Warning (Allergen) - <span lang=\"zh\">Bingquan</span> brand Ladies' Soy Drink recalled due to undeclared milk</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-23/eng/1450914001134/1450914006613\" title=\"Food Recall Warning (Allergen) - 2015-12-23\">Food Recall Warning (Allergen) - Chicken Veggie Pie and <span lang=\"fr\">Tourti\\xe8re</span> recalled due to undeclared milk and soy</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-23b/eng/1450922998982/1450923004317\" title=\"Food Recall Warning (Allergen) - 2015-12-23\">Food Recall Warning (Allergen) - Ho Ho Ho Food Products brand seafood products recalled due to undeclared egg</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-21/eng/1450731556477/1450731562281\" title=\"Food Recall Warning (Allergen) - 2015-12-21\">Food Recall Warning (Allergen) - Certain Glosette brand Raisins recalled due to undeclared peanut</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-18c/eng/1450507573695/1450507578970\" title=\"Updated Food Recall Warning (Allergen) - 2015-12-19\">Updated Food Recall Warning (Allergen) - Hai Pa Wang brand Frozen Fish Dumpling with Cuttlefish recalled due to undeclared egg and wheat</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-18b/eng/1450504262018/1450504267896\" title=\"Food Recall Warning (Allergen) - 2015-12-19\">Food Recall Warning (Allergen) - Soyspring brand Ladies' Soybean Drink recalled due to undeclared milk</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-19b/eng/1450590325536/1450590331480\" title=\"Food Recall Warning - 2015-12-19\">Food Recall Warning - Certain Bothwell brand shredded cheese products recalled due to <i lang=\"la\">Listeria monocytogenes</i></a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-19/eng/1450547016808/1450547021925\" title=\"Food Recall Warning - 2015-12-19\">Food Recall Warning - Ding Ho Foods brand seafood products recalled due to undeclared egg</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-18/eng/1450486912533/1450486918327\" title=\"Updated Food Recall Warning (Allergen) - 2015-12-18\">Updated Food Recall Warning (Allergen) - Taramosalata products recalled due to undeclared milk and sulphites</a>,\n",
       " <a href=\"/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2015-12-17/eng/1450413418110/1450413423680\" title=\"Food Recall Warning (Allergen) - 2015-12-17\">Food Recall Warning (Allergen) - Taramosalata products recalled due to undeclared milk and sulphites</a>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we isolated the table with the links we want, let's get just the links.\n",
    "links = links_table.find_all(\"a\")\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can start accessing each recall page. We just want the `href` attribute of the link, so we'll use BeautifulSoup to isolate it and pass it to requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    r_details = requests.get(\"http://www.inspection.gc.ca/\" + href)\n",
    "    soup_details = BeautifulSoup(r_details.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we got all the links to all recall details for a given year.\n",
    "\n",
    "Now we need to study the pages for each recall to see what data we want to extract from it.\n",
    "\n",
    "For this exercise, all I want are the details on the top of the page: date, reason for recall, hazard class, the company name, and where the product was distributed.\n",
    "\n",
    "Again, inspecting that element shows it's in a `<dl>` element with a class of \"dl-horizontal\". The details we want are in child `<dd>` nodes.\n",
    "\n",
    "<img src=\"img/details.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's load a single recall page to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dd class=\"mrgn-bttm-sm\">March 31, 2014</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">Allergen - Milk</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">Class 1</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">Altra Foods <abbr title=\"Incorporated\">Inc.</abbr>, Candy &amp; Chocolate Creations, Vancouver Judaica Group</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">Possibly National</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">Consumer</dd>,\n",
       " <dd class=\"mrgn-bttm-sm\">8747, 8755, 8760</dd>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\"http://www.inspection.gc.ca/about-the-cfia/newsroom/food-recall-warnings/complete-listing/2014-03-31/eng/1396319875632/1396319886479\")\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "# Right away we can isolate the dl and find all the dd's\n",
    "dl = soup.find(\"dl\", class_=\"dl-horizontal\")\n",
    "details = dl.find_all(\"dd\")\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful. Let's get the text content of each up to the line we care about (distribution). Look how easy it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 31, 2014\n",
      "Allergen - Milk\n",
      "Class 1\n",
      "Altra Foods Inc., Candy & Chocolate Creations, Vancouver Judaica Group\n",
      "Possibly National\n"
     ]
    }
   ],
   "source": [
    "for item in details[:5]:\n",
    "    print item.text\n",
    "\n",
    "# Again, item is a BeautifulSoup object with all the methods available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save each item to a variable and store it in the database of choice. I prefer CSVs. So putting everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for year 2013\n",
      "   Recall date: 18/12/2013\n",
      "   Recall date: 19/12/2013\n",
      "   Recall date: 10/05/2013\n",
      "   Recall date: 16/08/2013\n",
      "   Recall date: 16/05/2013\n",
      "   Recall date: 29/05/2013\n",
      "   Recall date: 23/05/2013\n",
      "   Recall date: 22/05/2013\n",
      "   Recall date: 21/05/2013\n",
      "   Recall date: 10/12/2013\n",
      "   Recall date: 09/12/2013\n",
      "   Recall date: 06/12/2013\n",
      "   Recall date: 06/12/2013\n",
      "   Recall date: 18/11/2013\n",
      "   Recall date: 15/11/2013\n",
      "   Recall date: 14/11/2013\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-91740f9f8403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Write the column headers in the CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reason\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"company\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"distribution\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mcycle_years\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2016\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-91740f9f8403>\u001b[0m in \u001b[0;36mcycle_years\u001b[0;34m(start_year, end_year)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mhref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mscrape_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# I use unicodecsv instead of csv because it handles unicode \n",
    "# without having to worry about encoding and decoding.\n",
    "# It's especially useful in Quebec where words have diacritics like é\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodecsv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Concatenate the URL up to 'ay=' with the year we want, then the tail end\n",
    "url_head = \"http://www.inspection.gc.ca/about-the-cfia/newsroom/food-recall-warnings/complete-listing/eng/1351519587174/1351519588221?ay=\"\n",
    "url_tail = \"&fr=0&fc=0&fd=0&ft=1\"\n",
    "\n",
    "def cycle_years(start_year, end_year):\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print \"Getting data for year {}\".format(str(year))\n",
    "        r = requests.get(url_head + str(year) + url_tail)\n",
    "        # Load the raw HTML into a BeautifulSoup object\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        links_table = soup.find(\"table\", class_ = \"table table-striped table-hover\")\n",
    "        links = links_table.find_all(\"a\")\n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "            scrape_details(href)\n",
    "            time.sleep(1)\n",
    "\n",
    "def scrape_details(href):\n",
    "    r = requests.get(\"http://www.inspection.gc.ca/\" + href)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    dl = soup.find(\"dl\", class_=\"dl-horizontal\")\n",
    "    details = dl.find_all(\"dd\")\n",
    "    # Convert text date into a Python datetime object\n",
    "    date = datetime.strptime(details[0].text, \"%B %d, %Y\")\n",
    "    reason = details[1].text\n",
    "    recall_class = details[2].text\n",
    "    company = details[3].text\n",
    "    distribution = details[4].text\n",
    "    print \"   Recall date: {}\".format(date.strftime(\"%d/%m/%Y\"))\n",
    "    writer.writerow([date, reason, recall_class, company, distribution])\n",
    "    \n",
    "\n",
    "f = open(\"recall_data.csv\", \"w\")\n",
    "writer = unicodecsv.writer(f)\n",
    "# Write the column headers in the CSV\n",
    "writer.writerow([\"date\", \"reason\", \"class\", \"company\", \"distribution\"])\n",
    "cycle_years(2013, 2016)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
